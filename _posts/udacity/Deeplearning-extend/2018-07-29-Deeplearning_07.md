---
layout: post
title: 【书】深度学习入门-07-卷积神经网络(ing)
date: 2018-07-28 00:00:07
categories: DeepLearning
tags: DeepLearning
---
* content
{:toc}

![image](https://user-images.githubusercontent.com/18595935/52058008-e3058000-25a9-11e9-8d0a-67377e60ab7d.png)

本章非常重要，主题是卷积神经网络(Convolutional Neural Network,CNN),CNN被用于图像识别，语音识别等各种场合。

# 1. 整体结构

之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这叫做“全连接(Fully-connected)”，另外我们使用的Affine层实现全连接层。

CNN中新出现了卷积层(Convolution)和池化层(Pooling)，对比的构造图如下：

![image](https://user-images.githubusercontent.com/18595935/52058940-d5e99080-25ab-11e9-9615-fe2523626abf.png)

> Affine层，进行仿射变换的处理。 神经网络的正向传播中进行矩阵的乘积运算在几何学中称为“仿射变换”。几何中，仿射变换包括一次线性变换和一次平移，分别对应神经网络的加权和运算与加偏置运算。
> ![image](https://user-images.githubusercontent.com/18595935/52058601-26142300-25ab-11e9-88f3-4441adae450e.png)

# 2. 卷积层

## 2.1 全连接层存在的问题

之前介绍的全连接神经网络中使用了全连接层(Affine层)，全连接存在什么问题呢？那就是数据的形状被忽视了，以MNIST数据集为例，高28像素长28像素的数据，会被排成一列，以784个数据的形式作为输入进行Affine层。
> 比如之前代码中的`print(x_train.shape)`，输出`(60000, 784)`

图像在空间上临近的像素为相似的值，RBG各个通道之间有密切的关联性等，这些重要的信息，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元处理，所以无法利用形状相关的信息。

而卷积层可以保持形状不变，当数据数据是图像时，卷积层会以3维数据的形式接收输入数据，并同样以3维数据的形式输出到下一层。

其中，卷积层的输入数据称为**输入特征图(input feature map)**，输出数据称为**输出特征图(output feature map)**。

## 2.2 卷积运算

卷积运算相同于图像处理中的滤波器运算，如下图：

![image](https://user-images.githubusercontent.com/18595935/52060730-295ddd80-25b0-11e9-8af4-760db3940bed.png)

如上图中，输入数据和滤波器一样，都是有高长方向上的维度，输入数据维度为(4,4)，滤波器为(3,3),输出数据为(2,2)。

对于输入数据，卷积运算以一定间隔滑动滤波器窗口并应用，如上面的各个色块，逐个滑动，滑动四次，分别和滤波器的元素相乘，然后再求和，最后将这个结果保存到输出的对应位置。这个运算叫做**乘积累加运算**。

**含有偏置的卷积运算**处理如下图：
> CNN中，滤波器的参数相当于权重，下图中，向应用了滤波器的数据加上了偏置，偏置通常只有1个(1*1),这个值会被加到应用了滤波器的所有元素上。

![image](https://user-images.githubusercontent.com/18595935/52061211-2e6f5c80-25b1-11e9-8479-e3aed27945c0.png)

## 2.3 填充

## 2.4 步幅

## 2.5 3维数据的卷积运算

## 2.6 结合方块思考

## 2.7 批处理

# 3. 池化层

# 4. 卷积层和池化层的实现

## 4.1 4维数组

## 4.2 基于im2col的展开

## 4.3 卷积层的实现

## 4.4 池化层的实现

# 5. CNN的实现

# 6. CNN的可视化

## 6.1 第一层权重的可视化

## 6.2 基于分层结构的信息提取

# 7. 具有代表性的CNN

## 7.1 LeNet

## 7.2 AlexNet



