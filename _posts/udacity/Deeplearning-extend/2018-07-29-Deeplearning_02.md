---
layout: post
title: 【书】深度学习入门-02-感知机(perceptron)
date: 2018-07-28 00:00:02
categories: DeepLearning
tags: DeepLearning
---
* content
{:toc}

感知机是神经网络(深度学习)的起源算法，学习感知机的构造，就是学习深度学习的一种重要思想。

下图是接收两个输入信号的感知机例子，输入信号被送往神经元时，会被分别乘以固定权重，神经元会计算传送过来信号的总和，当总和超过某个界限值时，才会输出1，这也称为`神经元被激活`，这里将这个界限值称为阈值，用符合`θ`表示。
- 权重w是控制输入信号的重要性的参数
- 阈值`θ`是调整神经元被激活的容易程度的参数

![image](https://user-images.githubusercontent.com/18595935/43525940-0082e368-95de-11e8-820a-00246e9319c1.png)

# 1. 简单逻辑电路

![image](https://user-images.githubusercontent.com/18595935/43527991-e311a74c-95e2-11e8-8ee4-fabb865e2d5b.png)

三个线性的感知器，只有参数，即权重和阈值不同，其结构都是相同的，都可以用上面的公式来表示，但是第四个异或感知器，没有一条线性能够同时划分0和1，为非线性结构。

# 2. 感知机的实现

```python
import numpy as np
# 一般的实现
def AND1(x1,x2):
    w1,w2,theta = 0.5,0.5,0.7
    tmp = x1*w2 + x2*w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1
    
# numpy矩阵实现
def AND2(x1,x2):
    x = np.array([x1,x2])
    w = np.array([0.5,0.5])
    b = -0.7
    tmp = np.sum(x*w) + b
    if tmp<=0:
        return 0
    else:
        return 1
```

其他两个感知器的实现方式一样，只是参数和阈值不同(权重w和偏置b)。

```python
def NAND(x1,x2):
    x = np.array([x1,x2])
    w = np.array([-0.5,-0.5])
    b = 0.7
    tmp = np.sum(x*w) + b
    if tmp<=0:
        return 0
    else:
        return 1

def OR(x1,x2):
    x = np.array([x1,x2])
    w = np.array([0.5,0.5])
    b = -0.2
    tmp = np.sum(x*w) + b
    if tmp<=0:
        return 0
    else:
        return 1
```

**什么是权重和偏置：**

![image](https://user-images.githubusercontent.com/18595935/51424236-733ce000-1c0e-11e9-9d0e-4a351a043817.png)

上面是一个感知机，w1和w2是权重，相当于电阻，电阻决定电流流动难度，在这里权重越大，对应该权重的信号重要性就越高。
θ是界限值，当总和超过这个界限值的时候输出1，称为神经元被激活。

![image](https://user-images.githubusercontent.com/18595935/51424281-cdd63c00-1c0e-11e9-9c13-e7d7a00b4a4f.png)

这个表达式与上面是完全相同的，b是-θ，b称为偏置，w1和w2称为权重。感知机会计算输入信号和权重的乘积，然后加上偏置，如果大于0则输出1，否则为0.

上面的代码就是使用了偏置和权重的实现。

1. 权重w1和w2是控制输入信号的重要性的参数，每个输入信号对应不同权重。
2. 偏置b是调整神经元被激活的容易程度的参数，一个神经元一个值。比如，如果b为-0.1，则只要输入信号的加权总和超过0.1，则神经元被激活。

# 3. 感知机的局限性

上面的四个感知器中，有三个线性，一个非线性，非线性无法用一条直线分开，如下图所示用一条曲线分割而成的空间称为非线性空间。

![image](https://user-images.githubusercontent.com/18595935/43528817-cf45a95a-95e4-11e8-97f7-a82b421c90c2.png)

下面的异或门，就无法用一条直线做出分割:

![image](https://user-images.githubusercontent.com/18595935/51424522-52768980-1c12-11e9-9467-630296ef948c.png)

机器学习中，线性/非线性这两个术语在机器学习领域很常见，像上面通过曲线分割而成的空间称为**非线性空间**，由直线分割而成的空间为**线性空间**。


# 4. 多层感知机

感知机不能表示异或门，但可以通过感知机的叠加层，如下图，通过and和or的叠加，可以实现上述非线性的空间。

![image](https://user-images.githubusercontent.com/18595935/43529463-53ceb620-95e6-11e8-88b6-070cdb5d3f1e.png)

代码实现如下：

```python
def XOR(x1,x2):
    s1 = NAND(x1,x2)
    s2 = OR(x1,x2)
    y = AND2(s1,s2)
    return y

print(XOR(0,0))
print(XOR(1,0))
print(XOR(0,1))
print(XOR(1,1))

```

输出结果如下，符合预期:

```python
0
1
1
0
```

叠加了多层的感知机也称为多层感知机(multi-layered perceptron)，通过叠加层，感知机能进行更加灵活的表示:

![image](https://user-images.githubusercontent.com/18595935/43529835-1a88ea92-95e7-11e8-8636-4651f5af00fb.png)

上面是一个2层感知机，现在第0层和第1层的神经元之间进行信号的传送和接收，然后在第1层和第2层之间进行信号的传送和接收，具体如下所示:

1. 第0层的两个神经元接收输入信号，并将信号发送到第1层神经元
2. 第1层的神经元将信号发送至第2层神经元，第2层的神经元输出y

多层感知机可以实现比之前见到的电路更复杂的电路，实际上，使用感知机甚至可以表示计算机。计算机是处理信息的机器，输入一些信息后，它会按照某种既定的方法进行处理，然后输出结果。

通常认为计算机内部的处理十分复杂，实际上只需要通过与非门的组合，就能再现计算机的处理，也就是说通过组合与非门可以实现计算机的话，通过组合感知机也可以表示计算机。

# 5. 小结

感知机是一种非常简单的算法，是学习神经网络的基础，通过叠加感知机能够进行复杂的非线性表示，理论上还可以表示计算机进行的处理。

- 感知机是具有输入和输出的算法，给定一个输入后，将输出一个既定的值。
- 感知机将权重和阈值设定为参数。
- 使用感知机可以表示与/或等逻辑电路。
- 异或无法通过单层感知机来表示，可以通过二层感知机表示异或门。
- 单层感知器只能表示非线性空间，而多层感知机可以表示非线性空间。
