---
layout: post
title: Uda-DeepLearning-U2-02-神经网络-实现梯度下降
date: 2018-05-05 00:00:00
categories: DeepLearning
tags: Udacity DeepLearning
---
* content
{:toc}

# 1. 平方平均误差函数

Luis讲述了对数损失函数。除此之外，还有很多其他误差函数都可以应用在神经网络中. 现在我们来介绍另一个，平方平均误差。从名字可以看出，它表示预测值和标签值的差的平方的平均值。接下来，我们会讲述更多细节，然后在学生录取数据集上实现向后传播算法。

# 2. 梯度下降

## 2.1 学习权重

![image](https://user-images.githubusercontent.com/18595935/43363900-29299f8c-934a-11e8-9d36-6ba2079c24b5.png)

## 2.2 注意事项

![image](https://user-images.githubusercontent.com/18595935/43363897-0a47cf80-934a-11e8-9501-72dce184c698.png)


# 3. 梯度下降：数学

通过误差平方和，衡量神经网络的预测效果。值越高，预测效果越差。

参考[损失函数-均方误差](http://road2ai.info/2018/07/28/Deeplearning_04/#2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0lost-function)

# 4. 梯度下降：代码

# 5. 实现梯度下降

# 6. 多层感知器

# 7. 反向传播

# 8. 实现一个反向传播

# 9. 进阶阅读

