---
layout: post
title: Nano01(自動運転)-U04-Lesson17-Keras
date: 2019-01-01 03:02:05
categories: self-driving(自動運転)
tags: self-driving
---
* content
{:toc}

如果说 Tensorflow 或者 Theano 神经网络方面的巨人. 那 Keras 就是站在巨人肩膀上的人. Keras 是一个兼容 Theano 和 Tensorflow 的神经网络高级包, 用他来组件一个神经网络更加快速, 几条语句就搞定了. 而且广泛的兼容性能使 Keras 在 Windows 和 MacOS 或者 Linux 上运行无阻碍。

# 0. 小结

本章比较简单，介绍了如何在Keras中创建神经网络，定义卷积层，池化层，dropout等。但是如果不了解神经网络的底层原理，那至多就是调参侠。

# 6. Neural Networks in Keras

## Sequential Model 连续模型

```python
from keras.models import Sequential

# Create the Sequential model
model = Sequential()
```

上面函数生成一个神经网络模型的warpper，提供一些通用功能，比如fit(),evaluate(),compile()等。

## Layers

一个Keras layer就是一个神经网络层，具体有fully connected layer,max pool layer,activation layer等，通过add()函数将layer添加到model上。

如下代码：

```python
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten

# Create the Sequential model
model = Sequential()

#1st Layer - Add a flatten layer
model.add(Flatten(input_shape=(32, 32, 3)))

#2nd Layer - Add a fully connected layer
model.add(Dense(100))

#3rd Layer - Add a ReLU activation layer
model.add(Activation('relu'))

#4th Layer - Add a fully connected layer
model.add(Dense(60))

#5th Layer - Add a ReLU activation layer
model.add(Activation('relu'))
```

对比TensorFlow中layer的生成方式，TensorFlow中需要逐层指定input的维度，以及其他参数，在Keras中能自动根据第一层进行推断。

1. `model.add(Flatten(input_shape=(32, 32, 3)))`，添加layer，其input是(32, 32, 3)，output是 (3072=32 x 32 x 3)。
2. `model.add(Dense(100))`，第二层使用上一层的output作为输入，将本层的输出维度设为100.


## Quiz

- Set the first layer to a Flatten() layer with the input_shape set to (32, 32, 3).
- Set the second layer to a Dense() layer with an output width of 128.
- Use a ReLU activation function after the second layer.
- Set the output layer width to 5, because for this data set there are only 5 classes.
- Use a softmax activation function after the output layer.
- Train the model for 3 epochs. You should be able to get over 50% training accuracy.

```python
import pickle
import numpy as np
import tensorflow as tf

# Load pickled data
with open('small_train_traffic.p', mode='rb') as f:
    data = pickle.load(f)
```

```python
# split data
X_train, y_train = data['features'], data['labels']
```

```python
# Setup Keras
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten
```

```python
# TODO: Build the Fully Connected Neural Network in Keras Here
model = Sequential()
model.add(Flatten(input_shape=(32, 32, 3)))
model.add(Dense(128))
model.add(Activation('relu'))

model.add(Dense(5))

model.add(Activation('softmax'))


# An Alternative Solution
# model = Sequential()
# model.add(Flatten(input_shape=(32, 32, 3)))
# model.add(Dense(128, activation='relu'))
# model.add(Dense(5, activation='softmax'))

```

```python
# preprocess data
X_normalized = np.array(X_train / 255.0 - 0.5 )

from sklearn.preprocessing import LabelBinarizer
label_binarizer = LabelBinarizer()
y_one_hot = label_binarizer.fit_transform(y_train)

model.compile('adam', 'categorical_crossentropy', ['accuracy'])
# TODO: change the number of training epochs to 3
history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)
```

输出：

```
Train on 80 samples, validate on 20 samples
Epoch 1/3
80/80 [==============================] - 0s 3ms/step - loss: 1.5198 - acc: 0.3125 - val_loss: 0.7062 - val_acc: 0.6500
Epoch 2/3
80/80 [==============================] - 0s 723us/step - loss: 0.7972 - acc: 0.5625 - val_loss: 0.5729 - val_acc: 0.8000
Epoch 3/3
80/80 [==============================] - 0s 708us/step - loss: 0.6151 - acc: 0.8375 - val_loss: 0.5225 - val_acc: 0.8000
```

```python
### DON'T MODIFY ANYTHING BELOW ###
### Be sure to run all cells above before running this cell ###
import grader

try:
    grader.run_grader(model, history)
except Exception as err:
    print(str(err))
```

```
Nice work!
Looks good!
```

## Quiz 示例代码

```python
'''Trains a simple deep NN on the MNIST dataset.
Gets to 98.40% test accuracy after 20 epochs
(there is *a lot* of margin for parameter tuning).
2 seconds per epoch on a K520 GPU.
'''

from __future__ import print_function

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

batch_size = 128
num_classes = 10
epochs = 20

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
```

# 7. Convolutions in Keras

## Quiz

- Build from the previous network.
- Add a convolutional layer with 32 filters, a 3x3 kernel, and valid padding before the flatten layer.
- Add a ReLU activation after the convolutional layer.
- Train for 3 epochs again, should be able to get over 50% accuracy.

```python
import pickle
import numpy as np
import tensorflow as tf

# Load pickled data
with open('small_train_traffic.p', mode='rb') as f:
    data = pickle.load(f)    
```

```python
# split data
X_train, y_train= data['features'], data['labels']
print(X_train.shape) # (100, 32, 32, 3)
```

```python
# Setup Keras
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten
from keras.layers.convolutional import Conv2D
```

```python
# TODO: Build Convolutional Neural Network in Keras Here
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=X_train.shape[1:]))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dense(5))
model.add(Activation('softmax'))
```

```python
# Preprocess data
X_normalized = np.array(X_train / 255.0 - 0.5 )

from sklearn.preprocessing import LabelBinarizer
label_binarizer = LabelBinarizer()
y_one_hot = label_binarizer.fit_transform(y_train)
```

```python
# compile and train model
# Training for 3 epochs should result in > 50% accuracy
model.compile('adam', 'categorical_crossentropy', ['accuracy'])
history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)
```

```
Train on 80 samples, validate on 20 samples
Epoch 1/3
80/80 [==============================] - 1s 10ms/step - loss: 1.3774 - acc: 0.4000 - val_loss: 0.9430 - val_acc: 0.6500
Epoch 2/3
80/80 [==============================] - 1s 6ms/step - loss: 0.9493 - acc: 0.6500 - val_loss: 0.4500 - val_acc: 0.8500
Epoch 3/3
80/80 [==============================] - 0s 6ms/step - loss: 0.4718 - acc: 0.8625 - val_loss: 0.3031 - val_acc: 0.8500
```

## Quiz 参考代码

```python
'''Trains a simple convnet on the MNIST dataset.
Gets to 99.25% test accuracy after 12 epochs
(there is still a lot of margin for parameter tuning).
16 seconds per epoch on a GRID K520 GPU.
'''

from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

batch_size = 128
num_classes = 10
epochs = 12

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
```

# 8. Pooling in Keras

## Quiz

> 其余代码与上面的示例相同

```python
# TODO: Build Convolutional Neural Network in Keras Here
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=X_train.shape[1:]))
model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dense(5))
model.add(Activation('softmax'))
```

# 9. Dropout in Keras

> 其余代码与上面的示例相同

```python
# TODO: Build Convolutional Neural Network in Keras Here
# Build Convolutional Pooling Neural Network with Dropout in Keras Here
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.5))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dense(5))
model.add(Activation('softmax'))
```

# 10. Testing in Keras

Once you've picked out your best model, it's time to test it!

```python
import pickle
import numpy as np
import tensorflow as tf

# Load pickled data
with open('small_train_traffic.p', mode='rb') as f:
    data = pickle.load(f)
```

```python
# Split the data
X_train, y_train = data['features'], data['labels']
```

```python
# Setup Keras
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten, Dropout
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
```

```python
# TODO: Build the Final Test Neural Network in Keras Here
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.5))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dense(5))
model.add(Activation('softmax'))
```

```python
# preprocess data
X_normalized = np.array(X_train / 255.0 - 0.5 )

from sklearn.preprocessing import LabelBinarizer
label_binarizer = LabelBinarizer()
y_one_hot = label_binarizer.fit_transform(y_train)
```

```python
# compile and fit the model
model.compile('adam', 'categorical_crossentropy', ['accuracy'])
history = model.fit(X_normalized, y_one_hot, epochs=8, validation_split=0.2)
```

输出：

```
...
Epoch 8/8
80/80 [==============================] - 0s 3ms/step - loss: 0.1088 - acc: 0.9625 - val_loss: 0.0777 - val_acc: 1.0000
```

**evaluate model against the test data：**

```python
# evaluate model against the test data
with open('small_test_traffic.p', 'rb') as f:
    data_test = pickle.load(f)

X_test = data_test['features']
y_test = data_test['labels']

# preprocess data
X_normalized_test = np.array(X_test / 255.0 - 0.5 )
y_one_hot_test = label_binarizer.fit_transform(y_test)

print("Testing")

metrics = model.evaluate(X_normalized_test, y_one_hot_test)
for metric_i in range(len(model.metrics_names)):
    metric_name = model.metrics_names[metric_i]
    metric_value = metrics[metric_i]
    print('{}: {}'.format(metric_name, metric_value))    
```

```python
Testing
20/20 [==============================] - 0s 599us/step
loss: 0.13371427357196808
acc: 0.949999988079071
```

