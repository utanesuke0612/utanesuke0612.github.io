---
layout: post
title: Nano01(自動運転)-U02-Lesson10-Project02-车道线检测进阶
date: 2019-01-01 01:03:08
categories: self-driving(自動運転)
tags: self-driving
---
* content
{:toc}

# 1. Tips and Tricks for the Project

在本章的学习中，掌握了新的方式去检测和追踪车道线信息，下面是在项目中需要使用的处理方法。

1. Camera calibration 摄像头校正

之前的课程和练习中已有涉及了，本项目中使用9×6的棋盘，而不是课程中的8×6。

2. 计算出来的斜率是否正确

计算出来的半径应该接近1km。

3. 偏移 offset

假设摄像头假设在车的中心部分，那么图像上检测出的两条车道线的中点，就是车道线的中心。从图像中心到车道线中心的偏移，就是车到车道线中心线的距离。

如下图,紫色圆点是车道线中心，黄色圆点是自车位置:

![image](https://user-images.githubusercontent.com/18595935/51160519-a3fcdc80-18d1-11e9-99ec-8dd7c93eb295.png)

4. 追踪

在测试图像上完成pipeline的创建后，我们要将其应用在video流上。
可以定义个类 Line去跟踪所有参数：

```python
# Define a class to receive the characteristics of each line detection
class Line():
    def __init__(self):
        # was the line detected in the last iteration?
        self.detected = False  
        # x values of the last n fits of the line
        self.recent_xfitted = [] 
        #average x values of the fitted line over the last n iterations
        self.bestx = None     
        #polynomial coefficients averaged over the last n iterations
        self.best_fit = None  
        #polynomial coefficients for the most recent fit
        self.current_fit = [np.array([False])]  
        #radius of curvature of the line in some units
        self.radius_of_curvature = None 
        #distance in meters of vehicle center from the line
        self.line_base_pos = None 
        #difference in fit coefficients between last and new fits
        self.diffs = np.array([0,0,0], dtype='float') 
        #x values for detected line pixels
        self.allx = None  
        #y values for detected line pixels
        self.ally = None  
```

5. Sanity(头脑清楚的) Check

往下一步之前，需要对检测结果进行check，检查如下结果：

- 是否有类似的斜率
- 是否它们是否被近似的正确的水平距离所分开  (懵逼状，啥意思...)
- 是否近似的平行

6. Look-Ahead(有预见性的) Filter

一旦在video的一帧图像中找到了车道线，而且相当自信找到的车道线是正确的，那么在下一帧图像中可以不需要盲找。

比如，如果匹配了一个多项式，那么对于每个y的位置，都有一个x位置可以表示其车道线中心。

7. Reset

8. 平滑处理

9. 描画

```python
# Create an image to draw the lines on
warp_zero = np.zeros_like(warped).astype(np.uint8)
color_warp = np.dstack((warp_zero, warp_zero, warp_zero))

# Recast the x and y points into usable format for cv2.fillPoly()
pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])
pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])
pts = np.hstack((pts_left, pts_right))

# Draw the lane onto the warped blank image
cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))

# Warp the blank back to original image space using inverse perspective matrix (Minv)
newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) 
# Combine the result with the original image
result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)
plt.imshow(result)
```


# 2. Project Instructions

- writeup
- code (or a Jupyter notebook)
- example output images
- output video

